# NN 모델 만들기
model = nn.Sequential(
          nn.Linear(2, 2, bias=True), nn.Sigmoid(),
          nn.Linear(2, 1, bias=True), nn.Sigmoid()).to(device)

#Wide ANN(Hidden layer을 2*2에서 2*10으로 변경)
model = nn.Sequential(
          nn.Linear(2, 10, bias=True), nn.Sigmoid(),
          nn.Linear(10, 1, bias=True), nn.Sigmoid()).to(device) #더빨리 수렴하지만 학습속도는 느려짐

#Shallow ANN(Hidden layer을 없애고 Single-layer Perceptron으로 변경)
model = nn.Sequential(
          nn.Linear(2, 1, bias=True), nn.Sigmoid()).to(device) #학습속도는 빠르지만 10,000epoch를 수행해도 문제를 풀지 못함

#Deep ANN(Hidden layer 층을 1개에서 2개로 변경)
model = nn.Sequential(
          nn.Linear(2, 2, bias=True), nn.Sigmoid(),
          nn.Linear(2, 2, bias=True), nn.Sigmoid(),
          nn.Linear(2, 1, bias=True), nn.Sigmoid()).to(device) #오래 걸리지만 학습됨

#DeeperANN(Hidden layer 층을 1개에서 2개로 변경)
model = nn.Sequential(
          nn.Linear(2, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 10, bias=True), nn.ReLU(), nn.Dropout(0.1),
          nn.Linear(10, 1, bias=True), nn.Sigmoid()).to(device) #10,000 epoch를 돌려도 학습이 안됨
# why?
# 2st winter seconds 시작 -> vanishing gradient
